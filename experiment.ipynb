{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 15 13:01:07 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.99                 Driver Version: 536.99       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P3              20W /  55W |      0MiB /  6144MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader,JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import os\n",
    "import json\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=\"8b9ea68a-fcc2-4d84-989a-f6b35212f328\"\n",
    "PINECONE_API_ENV=\"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_documents(documents):\n",
    "    document_objects = []\n",
    "    for doc in documents:\n",
    "        # Use .get() to handle missing keys with default values\n",
    "        product_info = f\"\"\"\n",
    "        Product Name: {doc.get('product_name', 'N/A')}\n",
    "        Price: {doc.get('product_price', 'N/A')}\n",
    "        Description: {doc.get('product_description', 'N/A')}\n",
    "        Artisan: {doc.get('artisan', 'N/A')}\n",
    "        Category: {doc.get('product_category', 'N/A')} ({doc.get('product_sub_category', 'N/A')})\n",
    "        Color: {doc.get('product_color', 'N/A')}\n",
    "        Size: {doc.get('product_size', 'N/A')}\n",
    "        Weight: {doc.get('product_weight', 'N/A')}\n",
    "        Material: {doc.get('product_material', 'N/A')}\n",
    "        Care Instructions: {doc.get('product_care', 'N/A')}\n",
    "        Craft: {doc.get('product_craft', 'N/A')}\n",
    "        \"\"\"\n",
    "        document_objects.append(Document(page_content=product_info.strip()))  # Create Document object\n",
    "    return document_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        documents = json.load(f)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_json(\"data/updated_itokri_small_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_objects = convert_to_documents(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(document_objects)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def hugging_face_embedding():\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\quant-chatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "d:\\Anaconda\\envs\\quant-chatbot\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding = hugging_face_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L12-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PINECONE_API_KEY'] = '8b9ea68a-fcc2-4d84-989a-f6b35212f328'\n",
    "index_name = \"vaani-chatbot\"\n",
    "\n",
    "docsearch=PineconeVectorStore.from_texts(\n",
    "    [t.page_content for t in text_chunks],\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PINECONE_API_KEY'] = '8b9ea68a-fcc2-4d84-989a-f6b35212f328'\n",
    "index_name = \"vaani-chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"Product Name: Beige - Kalamkari Block Printed Cotton Elasticated Pant\\n        Price: 1,390.00\\n        Description: Beige - Kalamkari Block Printed Cotton Elasticated Pant. Elasticated pant with a beautiful kalamkari block print. The pant is made from high quality cotton and has a comfortable fit. It is perfect for casual wear and can be paired with a kurta or a t-shirt.\\n        Artisan: Itokri Craft Initiative \\n        Category: Women's Fashion (Pants)\\n        Color: N/A\\n        Size: XL\"), Document(page_content=\"Product Name: Beige - Kalamkari Block Printed Cotton Kaftan With Tie-Up Waist (Medium)\\n        Price: 1,490.00\\n        Description: Beige - Kalamkari Block Printed Cotton Kaftan With Tie-Up Waist (Medium)\\n        Artisan: Itokri Craft Initiative \\n        Category: Women's Fashion (Kaftans)\\n        Color: N/A\\n        Size: Medium\\n        Weight: \\n        Material: Cotton\\n        Care Instructions: Hand Washable\\n        Craft: Kalamkari Block Print\")]\n"
     ]
    }
   ],
   "source": [
    "docsearch = Pinecone.from_existing_index(index_name,embedding)\n",
    "\n",
    "query = \"Beige - Kalamkari Block Printed Cotton Elasticated Pant\"\n",
    "\n",
    "docs=docsearch.similarity_search(query,k=2)\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"[INST] \n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say you don't know, and don't try to make up an answer.\n",
    "You are Vaani, an Indian handicraft e-commerce assistant, providing useful and concise information in two lines.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return a helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "[/INST]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(input_variables=[\"context\",\"question\"],template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs={\"prompt\":prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model=\"D:\\GenAi\\quantum_computing_chatbot\\model\\llama-2-13b-chat.ggmlv3.q5_0.bin\",\n",
    "                    model_type=\"llama\",\n",
    "                    config={'max_new_tokens':350,\n",
    "                            'temperature':0.5}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k':2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\"i wanna a handicraft from assam?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\quant-chatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Hello! If you're looking for a handicraft from Assam, I recommend the Assam Traditional Handloom Tussar Mekhela Chador With Blouse Piece 19. It's made of high-quality Tussar silk and features intricate Assamese weaving techniques. Plus, it's crafted by skilled artisan Sheikh Moidun Nilufar. Would you like to know more about this product?\n"
     ]
    }
   ],
   "source": [
    "result=qa({\"query\":user_input})\n",
    "print(\"Response: \",result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
